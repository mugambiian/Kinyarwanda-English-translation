{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiqsWwGJsaMd",
        "outputId": "4bf17487-6967-4a60-ae15-7fdba255a3f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive # Link your drive if you are a colab user\n",
        "drive.mount('/content/drive') # Models in this HW take a long time to get trained and make sure to save it her"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import random\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "MJ2f6rwgsgwH"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I have cleaned the data from my jupyter notebook\n",
        "df = pd.read_csv('/content/drive/MyDrive/Kinya_English_sentences.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xI9YatJJsgzd",
        "outputId": "ff3f7417-31fb-4606-ee33-c8bb56039f0a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         Kinyarwanda  \\\n",
              "0  Ababyeyi babo bamaze gupfa basogokuru barabare...   \n",
              "1  Waba uzi umubare wabantu bitabiriye kubyina ic...   \n",
              "2    Jya kuryama Ugomba kubyuka kare ejo mugitondo.    \n",
              "3    Nzasimbuza igihe cyatakaye nkora uko nshoboye.    \n",
              "4  Ngomba kumanika nonaha. Umuntu ategereje gukor...   \n",
              "\n",
              "                                             English  \n",
              "0  After their parents died their grandparents ra...  \n",
              "1  Do you know the number of people who attended ...  \n",
              "2  Go to bed You have to wake up early tomorrow m...  \n",
              "3     I will replace the lost time by doing my best.  \n",
              "4  I have to hang up now. Someone is waiting to u...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3afc6f3f-fd76-4c7a-804f-b42a50b5a634\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kinyarwanda</th>\n",
              "      <th>English</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ababyeyi babo bamaze gupfa basogokuru barabare...</td>\n",
              "      <td>After their parents died their grandparents ra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Waba uzi umubare wabantu bitabiriye kubyina ic...</td>\n",
              "      <td>Do you know the number of people who attended ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jya kuryama Ugomba kubyuka kare ejo mugitondo.</td>\n",
              "      <td>Go to bed You have to wake up early tomorrow m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nzasimbuza igihe cyatakaye nkora uko nshoboye.</td>\n",
              "      <td>I will replace the lost time by doing my best.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ngomba kumanika nonaha. Umuntu ategereje gukor...</td>\n",
              "      <td>I have to hang up now. Someone is waiting to u...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3afc6f3f-fd76-4c7a-804f-b42a50b5a634')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3afc6f3f-fd76-4c7a-804f-b42a50b5a634 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3afc6f3f-fd76-4c7a-804f-b42a50b5a634');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Kinyarwanda = list(df[\"Kinyarwanda\"])\n",
        "\n",
        "English = list(df[\"English\"])"
      ],
      "metadata": {
        "id": "_K3ubVE7txX-"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Kinyarwanda length {len(Kinyarwanda)}')\n",
        "print(f'English length {len(English)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxj-pZX5t3RV",
        "outputId": "8b2af061-9c55-475b-edee-20c8225aff26"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kinyarwanda length 25013\n",
            "English length 25013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_pairs = []\n",
        "for i in range(len(df)):\n",
        "  kiny, eng = df[\"Kinyarwanda\"][i], df[\"English\"][i]\n",
        "  eng = \"[start] \" + eng + \" [end]\"\n",
        "  text_pairs.append((kiny,eng))\n",
        "  \n",
        "text_pairs[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLb-BMqwyYgt",
        "outputId": "fef27016-c921-4073-f192-2174f64d2698"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Ababyeyi babo bamaze gupfa basogokuru barabareze. ',\n",
              "  '[start] After their parents died their grandparents raised them. [end]'),\n",
              " ('Waba uzi umubare wabantu bitabiriye kubyina icyumweru gishize? ',\n",
              "  '[start] Do you know the number of people who attended the dance last week? [end]'),\n",
              " ('Jya kuryama Ugomba kubyuka kare ejo mugitondo. ',\n",
              "  '[start] Go to bed You have to wake up early tomorrow morning. [end]'),\n",
              " ('Nzasimbuza igihe cyatakaye nkora uko nshoboye. ',\n",
              "  '[start] I will replace the lost time by doing my best. [end]')]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity Check\n",
        "for _ in range(5):\n",
        "    print(random.choice(text_pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvPpnGNRzlHi",
        "outputId": "70ba14f1-a302-4c4b-d075-7d45fb6d8395"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Mwebwe murashaka kwinezeza? ', '[start] Do you want to have fun? [end]')\n",
            "('Hari umuntu ushinzwe gusukura inzu', '[start] There is someone responsible for cleaning the house [end]')\n",
            "('Mfite ibintu byinshi ngomba gukora', '[start] I have many things I have to do [end]')\n",
            "('william azagera i Boston ejo nyuma ya saa sita', '[start] william will arrive in Boston tomorrow afternoon [end]')\n",
            "('Nzi neza ko ntigeze ntekereza ko  azakora ibintu nkibyo. ', '[start] I�m sure I never thought he would do such a thing. [end]')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sq--kTFuufU",
        "outputId": "227596f9-cffb-44e6-d68a-0c4c467cc765"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25013 total pairs\n",
            "17511 training pairs\n",
            "3751 validation pairs\n",
            "3751 test pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_Kiny_texts = [pair[0] for pair in train_pairs]\n",
        "train_Eng_texts = [pair[1] for pair in train_pairs]\n",
        "\n",
        "train_Kiny_texts[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4XV9HPCwHlA",
        "outputId": "e97122b2-ee75-4d58-f6e4-fa927d47daf9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Muganga yakubwiye kuguma mu buriri kugeza umuriro wawe ugabanutse sibyo? ',\n",
              " 'Umuhungu ntiyitaye ku nama za se',\n",
              " 'Yamujyanye mu gihugu cyabo Abalayiki ']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_Eng_texts[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joyuf9Zt1nK_",
        "outputId": "f82bc5df-179c-4c1d-8456-479c1b05228e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[start] Did the doctor tell you to stay in bed until your fever subsides right? [end]',\n",
              " \"[start] The boy did not pay attention to his father's advice [end]\",\n",
              " '[start] He took him to their own land [end]']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VECTORIZING THE TEXT DATA"
      ],
      "metadata": {
        "id": "q85h0pyfts8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = 5000\n",
        "sequence_length = 15\n",
        "batch_size = 8\n",
        "\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "\n",
        "Kiny_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size, \n",
        "    output_mode=\"int\", \n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "Eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_Kiny_texts = [pair[0] for pair in train_pairs]\n",
        "train_Eng_texts = [pair[1] for pair in train_pairs]\n",
        "Kiny_vectorization.adapt(train_Kiny_texts)\n",
        "Eng_vectorization.adapt(train_Eng_texts)"
      ],
      "metadata": {
        "id": "h5wWSpZMsg2Q"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aUIXquUsE-Mj"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(kiny, eng):\n",
        "    kiny = Kiny_vectorization(kiny)\n",
        "    eng = Eng_vectorization(eng)\n",
        "    return ({\"encoder_inputs\": kiny, \"decoder_inputs\": eng[:, :-1],}, eng[:, 1:])\n",
        "    return ({\"encoder_inputs\": kiny, \"decoder_inputs\": eng[:, :-1],}, eng[:, 1:])\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    Kiny_texts, Eng_texts = zip(*pairs)\n",
        "    Kiny_texts = list(Kiny_texts)\n",
        "    Eng_texts = list(Eng_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((Kiny_texts, Eng_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "metadata": {
        "id": "bwo0PB-tsg49"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check\n",
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7nd-p9esg71",
        "outputId": "8100d6ae-e144-413a-bcf2-8b29c98ed716"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (8, 15)\n",
            "inputs[\"decoder_inputs\"].shape: (8, 15)\n",
            "targets.shape: (8, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUILDING THE MODEL"
      ],
      "metadata": {
        "id": "WUdsvUUU3Hm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ],
      "metadata": {
        "id": "uyMZn7Gy3EKc"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we assemble the end-to-end model."
      ],
      "metadata": {
        "id": "1HN0UaAK4Oif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ],
      "metadata": {
        "id": "YP0qekU8sg_X"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training our model"
      ],
      "metadata": {
        "id": "4oZLefrh6da_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30  # This should be at least 30 for convergence\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LaJYx0_3Abf",
        "outputId": "669da510-929a-42ce-a9fc-9e6a261e00cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding_4 (Positi  (None, None, 256)   1283840     ['encoder_inputs[0][0]']         \n",
            " onalEmbedding)                                                                                   \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder_2 (Transfo  (None, None, 256)   3155456     ['positional_embedding_4[0][0]'] \n",
            " rmerEncoder)                                                                                     \n",
            "                                                                                                  \n",
            " model_5 (Functional)           (None, None, 5000)   7828360     ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder_2[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 12,267,656\n",
            "Trainable params: 12,267,656\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "2189/2189 [==============================] - 696s 316ms/step - loss: 3.5056 - accuracy: 0.2927 - val_loss: 3.4445 - val_accuracy: 0.2903\n",
            "Epoch 2/30\n",
            "2189/2189 [==============================] - 690s 315ms/step - loss: 3.4832 - accuracy: 0.2987 - val_loss: 3.4426 - val_accuracy: 0.2897\n",
            "Epoch 3/30\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 3.4999 - accuracy: 0.2945Epoch 4/30\n",
            "2189/2189 [==============================] - 687s 314ms/step - loss: 3.4979 - accuracy: 0.2979 - val_loss: 3.4612 - val_accuracy: 0.2861\n",
            "Epoch 5/30\n",
            "2189/2189 [==============================] - 688s 314ms/step - loss: 3.4906 - accuracy: 0.3013 - val_loss: 3.4579 - val_accuracy: 0.2863\n",
            "Epoch 6/30\n",
            "2189/2189 [==============================] - 687s 314ms/step - loss: 3.4842 - accuracy: 0.3051 - val_loss: 3.4698 - val_accuracy: 0.2873\n",
            "Epoch 7/30\n",
            "2189/2189 [==============================] - 694s 317ms/step - loss: 3.4819 - accuracy: 0.3065 - val_loss: 3.4740 - val_accuracy: 0.2917\n",
            "Epoch 8/30\n",
            "2189/2189 [==============================] - 695s 317ms/step - loss: 3.4767 - accuracy: 0.3085 - val_loss: 3.4512 - val_accuracy: 0.2943\n",
            "Epoch 9/30\n",
            "2189/2189 [==============================] - 690s 315ms/step - loss: 3.4714 - accuracy: 0.3105 - val_loss: 3.4612 - val_accuracy: 0.2948\n",
            "Epoch 10/30\n",
            "2189/2189 [==============================] - 694s 317ms/step - loss: 3.4773 - accuracy: 0.3106 - val_loss: 3.4769 - val_accuracy: 0.2953\n",
            "Epoch 11/30\n",
            "2189/2189 [==============================] - 690s 315ms/step - loss: 3.4794 - accuracy: 0.3088 - val_loss: 3.4833 - val_accuracy: 0.2930\n",
            "Epoch 12/30\n",
            "2189/2189 [==============================] - 688s 314ms/step - loss: 3.4704 - accuracy: 0.3131 - val_loss: 3.4742 - val_accuracy: 0.2954\n",
            "Epoch 13/30\n",
            "2189/2189 [==============================] - 695s 317ms/step - loss: 3.4725 - accuracy: 0.3140 - val_loss: 3.4645 - val_accuracy: 0.2997\n",
            "Epoch 14/30\n",
            "2189/2189 [==============================] - 696s 318ms/step - loss: 3.4413 - accuracy: 0.3204 - val_loss: 3.4548 - val_accuracy: 0.3031\n",
            "Epoch 15/30\n",
            " 946/2189 [===========>..................] - ETA: 6:16 - loss: 3.4581 - accuracy: 0.3202"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DECODING TEST SENTENCE"
      ],
      "metadata": {
        "id": "DoY4luoe7Qo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Eng_vocab = Eng_vectorization.get_vocabulary()\n",
        "Eng_index_lookup = dict(zip(range(len(Eng_vocab)), Eng_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = Kiny_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = Eng_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = Eng_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n"
      ],
      "metadata": {
        "id": "2nwg0zbv3Aes"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_Kiny_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(5):\n",
        "    input_sentence = random.choice(test_Kiny_texts)\n",
        "    translated = decode_sequence(input_sentence)"
      ],
      "metadata": {
        "id": "nkNLPcIF3AiD"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(3):\n",
        "    input_sentence = random.choice(test_Kiny_texts)\n",
        "    print(f'input Kinya sentence: {input_sentence}')\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(f'output translated in english: {translated}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xntWtkxZ9LLu",
        "outputId": "556f3a48-71de-4f56-f159-e9397d1226de"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input Kinya sentence: Yagenze vuba uko ashoboye kugira ngo amufate. \n",
            "output translated in english: [start] [UNK] is you [UNK] to be will be [end]\n",
            "input Kinya sentence: Kuki umuntu yakwifuza kuba inshuti? \n",
            "output translated in english: [start] why you you you will be will do [end]\n",
            "input Kinya sentence: Sinshaka guta aka gato. \n",
            "output translated in english: [start] i if you know to do do do you [end]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_Kiny_texts[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl1meLUd97hm",
        "outputId": "913888f4-2559-48e2-b967-0367d5c58878"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['iyo ukoresheje ibibabi byinshi wumva ',\n",
              " 'Nageze i Butara gusura marume',\n",
              " 'Ukanibagirana  cyane ndetse nkutarahageze']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SfaReP1a992h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}